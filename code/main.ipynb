{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# TRANSCRIPT.IA: KNOWLEDGE IS ALL YOU NEED\n",
    "#### Overview of the project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](../images/Untitled-2024-10-12-1138.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import vectorstore\n",
    "import transcription\n",
    "import chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we are setting the model. \n",
    "##### Bear in mind that the OPENAI_API_KEY, PINECONE_API_KEY keys should be defined in the test.env file. For streamlit, they should be stated in the corresponding section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelpalospou/Desktop/Data_projects/code/model.py:12: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_output=model.model()\n",
    "\n",
    "model, OPENAI_API_KEY, PINECONE_API_KEY = model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's input the youtube video we want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_link = input(\"Please enter the YouTube link (in quotes): \")\n",
    "transcription_output=transcription.transcription(youtube_link, \"transcription\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are creating the vectorstore in PINECONE\n",
    "##### Please provide the name of the index or database we want to create in our pinecone account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = input(\"Please enter the name of the next index to create\")\n",
    "vector = vectorstore.vectorstore(PINECONE_API_KEY, index_name, transcription_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jordan Peterson suggests that when God creates the world, He sees that it is good. This raises the fundamental question of whether the world is indeed good, especially when considering the implications of bringing a child into it. He acknowledges the complexity of this question and the necessity of making a fundamental statement of faith regarding the goodness of the world.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = input(\"What would you like to ask?\")\n",
    "chain=chains.chains(vector, question, model)\n",
    "print(chain)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
